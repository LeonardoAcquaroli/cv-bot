{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "#creates a persistent instance of Chroma that saves data to disk, useful for testing and development\n",
    "chromadb_client = chromadb.PersistentClient(path=\"./Chroma_collections\")\n",
    "collection = chromadb_client.get_or_create_collection(name=\"cv-bot-db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 in the collection\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "#Openai Embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "langchain_chroma = Chroma(\n",
    "    client=chromadb_client,\n",
    "    collection_name=\"cv-bot-db\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "print(\"There are\", langchain_chroma._collection.count(), \"in the collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "doc_folder = r'C:\\Users\\leoac\\OneDrive\\Work\\CV\\cv-bot\\docs'\n",
    "\n",
    "#load data onto collection\n",
    "#create some metadata, chunck text and embedded it\n",
    "\n",
    "for counter, filename in enumerate(os.listdir(doc_folder), start=1):\n",
    "    file_path = os.path.join(doc_folder, filename)\n",
    "    loader = TextLoader(file_path, encoding='utf-8')\n",
    "    data = loader.load()\n",
    "    \n",
    "    # generate document id\n",
    "    document_id = f'id{counter}'\n",
    "    #extract title\n",
    "    document_title = filename.split('.')[0] \n",
    "\n",
    "    #splitter mode, chunk_size=maximum number of tokens, chunk_overlay between two chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, add_start_index=True)\n",
    "    all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "    for doc_index, doc in enumerate(all_splits, start=1):\n",
    "        # Aggiungi i metadati esistenti\n",
    "        doc.metadata.update({'document_id': document_id, 'title': document_title})\n",
    "        # Crea e aggiungi un chunk_id univoco \n",
    "        chunk_id = f'{document_id}_chunk{doc_index}'\n",
    "        doc.metadata['chunk_id'] = chunk_id\n",
    "    \n",
    "    # Poi, passa all_splits direttamente a langchain_chroma\n",
    "    langchain_chroma.add_documents(all_splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Leonardo's skills\"\n",
    "embedding_vector = embeddings.embed_query(query) #--> in this case i have created a vector from the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents: 2\n"
     ]
    }
   ],
   "source": [
    "docs = langchain_chroma.similarity_search_by_vector(embedding_vector, k=2)\n",
    "print(f\"Retrieved documents: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use retrieved text in chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "template = \"\"\"\n",
    "            Given the following extracted parts of a long document and a question, create a final answer only with the context information.\n",
    "\n",
    "            {context}\n",
    "\n",
    "            {chat_history}\n",
    "            Human: {human_input}\n",
    "            Chatbot:\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0,\n",
    "                 model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"chat_history\", \"human_input\", \"context\"],\n",
    "                        template=template)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",\n",
    "                                  input_key=\"human_input\")\n",
    "\n",
    "#stuff= i use all chunk retrived without any preprocessing\n",
    "chain = load_qa_chain(llm,\n",
    "                      chain_type=\"stuff\",\n",
    "                      memory=memory,\n",
    "                      prompt=prompt)\n",
    "\n",
    "retriever = langchain_chroma.as_retriever(search_type='mmr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 4, updating n_results = 4\n"
     ]
    }
   ],
   "source": [
    "query=\"Leonardo's skills\"\n",
    "docs = retriever.invoke(query)\n",
    "output = chain.invoke({\"input_documents\": docs, \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Leonardo has advanced skills in Statistics & Machine Learning, Computer Vision, and Reinforcement Learning. He is proficient in Python, R, SQL, and Excel, and has excellent public speaking abilities.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['output_text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
